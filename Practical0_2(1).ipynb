{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Practical0-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7voDCJZJ9XVD"
      },
      "source": [
        "# Practical 0\n",
        "## Part II. Exploring data with Pandas\n",
        "\n",
        "Before we start building models using machine learning libraries such as Scikit-learn or Tensorflow, we might always need to explore and clean the data. \n",
        "\n",
        "In Part II of the worksheet, we will use Pandas to explore an example dataset - Titanic Disaster data, taken from [Kaggle Competition](https://www.kaggle.com/c/titanic/overview), for predicting the likelihood for a person to survive given some ticket information.\n",
        "\n",
        "\n",
        "In this practical, we will guide you through the use of this package - but in the future we do expect you to make use of the package's documentation. This can be found here:\n",
        "https://pandas.pydata.org/pandas-docs/stable/\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3u2I56J9XVM"
      },
      "source": [
        "### Hello Pandas\n",
        "Pandas is a Python library that contains high-level data structures and manipulation tools designed for data analysis. Think of Pandas as a Python version of Excel. Scikit-learn, on the other hand, is an open-source machine learning library for Python. While Scikit-learn does a lot of the heavy lifting, what's equally important is ensuring that raw data is processed in such a way that we are able to 'feed' it to Scikit-learn. Hence, the ability to manipulate raw data with Pandas makes it an indispensible part of our toolkit.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "_j3wW_zW9XVM"
      },
      "source": [
        "import pandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg5vv5ilm2TC"
      },
      "source": [
        "Whilst this is an acceptable way of loading in the library, when working with large projects it can be a bit tiresome to write ```pandas``` in full every time you are required to leverage on the library. Fortunately for us, we can make use of ```as``` when importing the library to shorten the call. We can do this by doing the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "gFFtT6pM9XVN"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSMdqD_79XVN"
      },
      "source": [
        "Now we load the data:\n",
        "\n",
        "As the data is in the form of a comma-seperated value (csv) file, we will make use of pandas' read_csv function. Documentation for this can be found here:\n",
        "\n",
        "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "6XXY10vd9XVO"
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/ashishpatel26/Titanic-Machine-Learning-from-Disaster/master/input/train.csv\"\n",
        "data = pd.read_csv(url, sep=\",\")\n",
        "\n",
        "# View the data frame within a cell\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P57FuolgnIfG"
      },
      "source": [
        "# Your code: Check the shape of the data\n",
        "# \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rG1KC_p09XVO"
      },
      "source": [
        "## Data Exploration\n",
        "\n",
        "Before building a model, we want to explore the data first: some data cleaning, visualisation and simple statistics will be useful here. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0XmYn3geQdX"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46lRes2k9XVP"
      },
      "source": [
        "And to just get a quick glimpse of the data that we have loaded, we can just call ```data.head(n_rows)``` where ```n_rows``` is equal to the number of rows we want to see."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns5nDdbX9XVP"
      },
      "source": [
        "data.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOUn7J1u9XVQ"
      },
      "source": [
        "Before we feed our data into a classifier, we first have to do a bit of  manipulation to the ```DataFrame``` object. For the purposes of this practical we will convert much of the string data into categorical data. This is a fairly simple task in which we can leverage ```numpy``` to make things easier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JT1Ym3bG9XVQ"
      },
      "source": [
        "# Drop the irelevant variables \n",
        "# - Note that the column names are case sensitive here\n",
        "data = data.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
        "\n",
        "data.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMDAjhFIqK3f"
      },
      "source": [
        "# Fill in missing values with a mean\n",
        "age_mean = data['Age'].mean()\n",
        "data['Age'] = data['Age'].fillna(age_mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X23IaF8qIol"
      },
      "source": [
        "from scipy.stats import mode\n",
        "\n",
        "# Fill in missing values with mode for discrete variables\n",
        "mode_embarked = mode(data['Embarked'])[0][0]\n",
        "data['Embarked'] = data['Embarked'].fillna(mode_embarked)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgI0z3f49XVS"
      },
      "source": [
        "As there are only two unique values for the column Sex, we have no problems of ordering."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1XJZqfN9XVU"
      },
      "source": [
        "data['gender'] = data['Sex'].map({'female': 0, 'male': 1}).astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iR4a-6H9XVV"
      },
      "source": [
        "For the column Embarked, however, replacing {C, S, Q} by {1, 2, 3} would seem to imply the ordering C < S < Q when in fact they are simply arranged alphabetically.\n",
        "\n",
        "To avoid this problem, we create dummy variables. Essentially this involves creating new columns to represent whether the passenger embarked at C with the value 1 if true, 0 otherwise. Pandas has a built-in function to create these columns automatically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm4v0jHJ9XVV"
      },
      "source": [
        "pd.get_dummies(data['Embarked'], prefix='Embarked').head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFnFcsCK9XVW"
      },
      "source": [
        "data = pd.concat([data, pd.get_dummies(data['Embarked'], prefix='Embarked')], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9VT9Qaa9XVX"
      },
      "source": [
        "Exercise:\n",
        "\n",
        "Write the code to create dummy variables for the column Sex."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "zLgjUmxd9XVY"
      },
      "source": [
        "# Your code here\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxiaCWhS9XVY"
      },
      "source": [
        "data = data.drop(['Sex', 'Embarked'], axis=1)\n",
        "\n",
        "# Put column name to a list\n",
        "cols = data.columns.tolist()\n",
        "\n",
        "# Reoder the column names and the dataframe (data) according the new column order\n",
        "cols = [cols[1]] + cols[0:1] + cols[2:]\n",
        "data = data[cols]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQmevhj_9XVY"
      },
      "source": [
        "We review our processed training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPJoNdqf9XVZ"
      },
      "source": [
        "data.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBbyj5r39XVZ"
      },
      "source": [
        "# Summarise the dataset: descriptive statistics\n",
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z76KZ-9d9XVZ"
      },
      "source": [
        "### Visualising the data\n",
        "Data visualisation can be performed using Pandas and Matplotlib. Another popular libraries for data visualisation is [Seaborn](https://jakevdp.github.io/PythonDataScienceHandbook/04.14-visualization-with-seaborn.html) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "e2A3Viaa9XVZ"
      },
      "source": [
        "# %matplotlib inline: To make matplotlib inline graphics\n",
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mswZlO5a9XVa"
      },
      "source": [
        "# Histograms for checking the distributions of the variables.\n",
        "data.Survived.value_counts()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neG6okZ4sJ46"
      },
      "source": [
        "\n",
        "# Plot the histogram\n",
        "data.Survived.value_counts().plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "YD28VCxk9XVa"
      },
      "source": [
        "y = data[\"Survived\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oa_bOI09XVa"
      },
      "source": [
        "data['Age'].plot(kind='hist') # Histogram for age"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkEnM52F9XVa"
      },
      "source": [
        "# Boxplots to compare the distribution of continuous variables by groups\n",
        "data.boxplot(column='Age', by='Survived')\n",
        "data.boxplot(column='Fare', by='Survived')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ITsWyoD9XVb"
      },
      "source": [
        "# Scatter plots\n",
        "# Visualise the data by groups in colors\n",
        "df0=data[data['Survived']==0] # subset of data\n",
        "df1=data[data['Survived']==1] # subset of data\n",
        "ax = df0.plot(kind='scatter', x='Age', y='Fare', color='green', label='survived')\n",
        "df1.plot(kind='scatter', x='Age', y='Fare', color='red', label='Not Survived', ax=ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGQdQw6D9XVb"
      },
      "source": [
        "Exercise:\n",
        "\n",
        "What are the other variables that you would like to visualise in order to understand the association between those variables and survival data? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "fYhqWeJd9XVb"
      },
      "source": [
        "# Your answer or code here\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mu3U-FGe9XVb"
      },
      "source": [
        "Now using the code above, analyse the column definitions and determine what features you would like to use for predicting if a person would survive or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uj3gTz7d9XVb"
      },
      "source": [
        "X = data.values[:,1:] # remember to exclude the output column (the first column here)\n",
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t5DFnf79XVb"
      },
      "source": [
        "Now we can check to see whether or not this data has been set up correctly by ensuring that there are a equal amount of samples in both ```X``` and ```y```. If this throws and exception, alter your code to make it work. If you are still stuck, call over a demonstrator to help."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ImDnNFpQ9XVb"
      },
      "source": [
        "if X.shape[0] != y.shape[0]:\n",
        "    raise Exception(\"Sample counts do not align! Try again!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylK08f2_3Ev7"
      },
      "source": [
        "## Colab Specific\n",
        "\n",
        "You can mount your Google Drive as a VM local drive. You can save your notebooks in your Drive, or directly to your GitHub repositories, or simply download them locally.\n",
        "\n",
        "For more instruction, see https://colab.research.google.com/notebooks/io.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnhsWLG2VHyx",
        "outputId": "a55d6e33-5d2b-4db9-ec54-aba254815631"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89AIcFI4c6Gm",
        "outputId": "7cd083b0-1a8f-450c-b157-1b5c8c741788"
      },
      "source": [
        "!ls /content/gdrive/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnBZMQgK8Yrc"
      },
      "source": [
        "You can access to your Drive files using this path (and try click on the link) \"/content/gdrive/MyDrive/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeuGtGCZ9XVg"
      },
      "source": [
        "## Helpers\n",
        "\n",
        "### Pandas Cheatsheet\n",
        "https://github.com/pandas-dev/pandas/blob/master/doc/cheatsheet/Pandas_Cheat_Sheet.pdf\n",
        "\n",
        "\n",
        "### List slicing tips\n",
        "\n",
        "If you're new to the python programming language, understanding list slicing may be a bit difficult. Here's a quick guide.\n",
        "\n",
        "Given the following list:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "zu5gmZYl9XVg"
      },
      "source": [
        "l = [\"This\", \"is\", \"a\", \"list\", \"of\", \"strings\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoUiMz479XVg"
      },
      "source": [
        "If I wanted to get the first element of that list, I'd simply:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5_LT6mk9XVh"
      },
      "source": [
        "l[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqQbk0Ix9XVh"
      },
      "source": [
        "If I wanted to get the last element of that list, I'd simply:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyxqToYt9XVh"
      },
      "source": [
        "l[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioJbbilm9XVh"
      },
      "source": [
        "If I wanted to get everything after the first element:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chaY55Bt9XVh"
      },
      "source": [
        "l[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O5kIuT49XVh"
      },
      "source": [
        "And if I wanted to get everything before the last element:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIWWnwwV9XVi"
      },
      "source": [
        "l[:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni5hRBgh9XVi"
      },
      "source": [
        "And finally, everything after the first and before the last:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jPPpIk59XVi"
      },
      "source": [
        "l[1:-1]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}